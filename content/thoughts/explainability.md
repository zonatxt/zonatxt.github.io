---
title: "Explainability"
date: 2021-10-11
tags:
  - sapling
aliases:
  - interpretability
---

[European Union adopted new data-protection rules](https://arxiv.org/abs/1606.08813) in 2016 that include a legal right to an explanation of decisions made by algorithms.

As AI systems become more influential in their power and incorporated into more and more important decision making, explainability is extremely important for the sake of algorithmic [accountability](thoughts/accountability.md).

For now though, the current advances in deep learning mean that most representations of the neural network state have a distributed [representation](thoughts/representation.md) of content, meaning that there is no 'single-neuron' for certain decisions as semantic symbols do not arise here.

[[thoughts/semantics|Semantic]] meaning only arises in [[thoughts/neural networks|neural networks]] because we inject them or through inductive proding (e.g. LIME for explainability)
